{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16389d55",
   "metadata": {},
   "source": [
    "First it'd be best to setup the environment. I've copied the raw courses from: \n",
    "https://gist.github.com/pat-coady/26fafa10b4d14234bfde0bb58277786d\n",
    "\n",
    "Because this would take a while and be pretty tedious to do myself.\n",
    "\n",
    "But we'd still need to convert this to some other format. \n",
    "\n",
    "I think the best thing to do first would be to setup the environment, then from there work on the reinforcement learning part of it.\n",
    "\n",
    "Now that the environment is setup, we need to setup the target and behaviour policies.\n",
    "\n",
    "The target will just be a greedy deterministic policy.\n",
    "\n",
    "The behaviour policy will be epsilon greedy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e09a7ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Racetracks\n",
    "\n",
    "# Left Race Track from Figure 5.5\n",
    "big_course = ['WWWWWWWWWWWWWWWWWW',\n",
    "              'WWWWooooooooooooo+',\n",
    "              'WWWoooooooooooooo+',\n",
    "              'WWWoooooooooooooo+',\n",
    "              'WWooooooooooooooo+',\n",
    "              'Woooooooooooooooo+',\n",
    "              'Woooooooooooooooo+',\n",
    "              'WooooooooooWWWWWWW',\n",
    "              'WoooooooooWWWWWWWW',\n",
    "              'WoooooooooWWWWWWWW',\n",
    "              'WoooooooooWWWWWWWW',\n",
    "              'WoooooooooWWWWWWWW',\n",
    "              'WoooooooooWWWWWWWW',\n",
    "              'WoooooooooWWWWWWWW',\n",
    "              'WoooooooooWWWWWWWW',\n",
    "              'WWooooooooWWWWWWWW',\n",
    "              'WWooooooooWWWWWWWW',\n",
    "              'WWooooooooWWWWWWWW',\n",
    "              'WWooooooooWWWWWWWW',\n",
    "              'WWooooooooWWWWWWWW',\n",
    "              'WWooooooooWWWWWWWW',\n",
    "              'WWooooooooWWWWWWWW',\n",
    "              'WWooooooooWWWWWWWW',\n",
    "              'WWWoooooooWWWWWWWW',\n",
    "              'WWWoooooooWWWWWWWW',\n",
    "              'WWWoooooooWWWWWWWW',\n",
    "              'WWWoooooooWWWWWWWW',\n",
    "              'WWWoooooooWWWWWWWW',\n",
    "              'WWWoooooooWWWWWWWW',\n",
    "              'WWWoooooooWWWWWWWW',\n",
    "              'WWWWooooooWWWWWWWW',\n",
    "              'WWWWooooooWWWWWWWW',\n",
    "              'WWWW------WWWWWWWW']\n",
    "\n",
    "# Tiny course for debug\n",
    "\n",
    "tiny_course = ['WWWWWW',\n",
    "               'Woooo+',\n",
    "               'Woooo+',\n",
    "               'WooWWW',\n",
    "               'WooWWW',\n",
    "               'WooWWW',\n",
    "               'WooWWW',\n",
    "               'W--WWW',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06fd357",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "zeros() missing required argument 'shape' (pos 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[141]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    103\u001b[39m                 done = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    105\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m path\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m behaviour_policy = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: zeros() missing required argument 'shape' (pos 0)"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random.seed(1)\n",
    "\n",
    "class RaceTrack:\n",
    "    def __init__(self, course: list[str]):\n",
    "        self.course = self._load_course(course)\n",
    "        self.car_location = self._start()\n",
    "        self.velocity = (0, 0)\n",
    "\n",
    "    def _load_course(self, string_course: list[str]) -> np.array:\n",
    "        course = np.zeros((len(string_course), len(string_course[0])), dtype=np.int16)\n",
    "        course_dict = {\"W\": -1, \"o\": 0, \"-\": 1, \"+\": 2}\n",
    "\n",
    "        for i in range(len(course)):\n",
    "            for j in range(len(course[i])):\n",
    "                course[i, j] = course_dict[string_course[i][j]]\n",
    "\n",
    "        return course\n",
    "    \n",
    "    def _start(self) -> tuple[int, int]:\n",
    "        rows, cols = np.where(self.course == 1)\n",
    "        coords = list(zip(rows, cols))\n",
    "        start = random.randint(0, len(coords)-1)\n",
    "\n",
    "        return coords[start]\n",
    "    \n",
    "    def _restart(self):\n",
    "        self.car_location = self._start()\n",
    "        self.velocity = (0, 0)\n",
    "\n",
    "    def get_course(self) -> np.array:\n",
    "        return self.course\n",
    "    \n",
    "    def apply_velocity(self, action: tuple[int, int]):\n",
    "        y_vel = min(max(self.velocity[0] + action[0], 0), 5) # Bound to between 0-5\n",
    "        x_vel = min(max(self.velocity[1] + action[1], 0), 5)\n",
    "        self.velocity = (y_vel, x_vel)\n",
    "\n",
    "    def apply_movement(self) -> str:\n",
    "        result = self.check_bounds()\n",
    "\n",
    "        if result == \"invalid\":\n",
    "            self._restart()\n",
    "            return \"restarted\"\n",
    "        elif result == \"complete\":\n",
    "            return \"done\"\n",
    "        else:\n",
    "            return \"continuing\"\n",
    "    \n",
    "    def check_bounds(self) -> str:\n",
    "        self.velocity = (5, 5)\n",
    "        y_vel, x_vel = self.velocity\n",
    "        y, x = self.car_location\n",
    "\n",
    "        all_positions = []\n",
    "        max_vel = max(x_vel, y_vel)\n",
    "        y_vel_count, x_vel_count = y_vel, x_vel\n",
    "        y_temp, x_temp = y, x\n",
    "\n",
    "        for _ in range(max_vel):\n",
    "            if y_vel_count > 0 and x_vel_count > 0:\n",
    "                y_temp -= 1\n",
    "                x_temp += 1\n",
    "                all_positions.append((y_temp, x_temp))\n",
    "                y_vel_count -= 1\n",
    "                x_vel_count -= 1\n",
    "            elif y_vel_count > 0:\n",
    "                y_temp -= 1\n",
    "                all_positions.append((y_temp, x_temp))\n",
    "                y_vel_count -= 1\n",
    "            else:\n",
    "                x_temp += 1\n",
    "                all_positions.append((y_temp, x_temp))\n",
    "                x_vel_count -= 1\n",
    "\n",
    "        all_position_values = []\n",
    "\n",
    "        for i, j in all_positions:\n",
    "            all_position_values.append(self.get_course()[i, j])\n",
    "\n",
    "        if -1 in all_position_values:\n",
    "            return \"invalid\"\n",
    "        elif 2 in all_position_values:\n",
    "            return \"complete\"\n",
    "        else:\n",
    "            self.car_location = all_positions[-1]\n",
    "            return \"valid\"\n",
    "\n",
    "    def random_episode(self) -> list:\n",
    "        self.car_location = self._start()\n",
    "        actions = [(x, y) for x in range(-1, 2) for y in range(-1, 2)]\n",
    "        done = False\n",
    "        path = []\n",
    "\n",
    "        while not done:\n",
    "            action = actions[random.randint(0, len(actions)-1)]\n",
    "            self.apply_velocity(action)\n",
    "            result = self.apply_movement()\n",
    "            path.append(self.car_location)\n",
    "\n",
    "            if result == \"done\":\n",
    "                done = True\n",
    "        \n",
    "        return path\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9905c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "course = big_course\n",
    "# Setup q values\n",
    "q_values= np.zeros((len(course[0]), len(course), 5, 5, 3, 3)) # len(x), len(y), 5 speeds up and down, 3 possible actions for x and y axis. If it were state values, we'd just need v = x, y, 5, 5\n",
    "c_values = np.zeros(q_values.shape) # Need the same shape for our running importance sampling sum\n",
    "actions = [(x, y) for x in range(-1, 2) for y in range(-1, 2)]\n",
    "\n",
    "target_policy = np.zeros((len(course[0]), len(course), 5, 5)) + 4 # Need an array for each state, default value set to (0, 0)\n",
    "behaviour_policy = np.zeros(target_policy.shape) + (1/9) # Begin as equiprobable policy\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
